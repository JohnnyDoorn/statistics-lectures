# $\chi^2$ test {.section}

Relation between categorical variables

## $\chi^2$ test {.smaller}

A '''chi-squared test''', also written as $\chi^2$ test, is any statistical hypothesis test wherein the sampling distribution of the test statistic is a chi-squared distribution when the null hypothesis is true. Without other qualification, 'chi-squared test' often is used as short for Pearson's chi-squared test.

Chi-squared tests are often constructed from a Lack-of-fit sum of squares#Sums of squares|sum of squared errors, or through the Variance Distribution of the sample variance|sample variance. Test statistics that follow a chi-squared distribution arise from an assumption of independent normally distributed data, which is valid in many cases due to the central limit theorem. A chi-squared test can be used to attempt rejection of the null hypothesis that the data are independent.

Source: [wikipedia](https://en.wikipedia.org/wiki/Chi-squared_test)

## $\chi^2$ test statistic {.subsection}

$$\chi^2 = \sum \frac{(\text{observed}_{ij} - \text{model}_{ij})^2}{\text{model}_{ij}}$$

### Contingency table

<table style="width:700px;">
<tr><td>

$$\text{observed}_{ij} = 
 \begin{pmatrix}
  o_{11} & o_{12} & \cdots & o_{1j} \\
  o_{21} & o_{22} & \cdots & o_{2j} \\
  \vdots & \vdots & \ddots & \vdots \\
  o_{i1} & o_{i2} & \cdots & o_{ij} 
 \end{pmatrix}$$
 
 </td><td>
 
 $$\text{model}_{ij} = 
 \begin{pmatrix}
  m_{11}  & m_{12} & \cdots & m_{1j} \\
  m_{21}  & m_{22} & \cdots & m_{2j} \\
  \vdots  & \vdots & \ddots & \vdots \\
  m_{i1}  & m_{i2} & \cdots & m_{ij} 
 \end{pmatrix}$$
 
 </td></tr>
 </table>

## $\chi^2$ distribution {.smaller .subsection}

The $\chi^2$ distribution describes the test statistic under the assumption of $H_0$, given the degrees of freedom. 

$df = (r - 1) (c - 1)$ where $r$ is the number of rows and $c$ the amount of columns.

```{r}
chi = seq(0,8,.01)
df  = c(1,2,3,6,8,10)
col = rainbow(n = length(df))

plot( chi, dchisq(chi, df[1]), lwd = 2, col = col[1], type="l",
      main = "Chi squared distributions",
      ylab = "Density",
      ylim = c(0,1),
      xlab = "Chi squared")

lines(chi, dchisq(chi, df[2]), lwd = 2, col = col[2], type="l")
lines(chi, dchisq(chi, df[3]), lwd = 2, col = col[3], type="l")
lines(chi, dchisq(chi, df[4]), lwd = 2, col = col[4], type="l")
lines(chi, dchisq(chi, df[5]), lwd = 2, col = col[5], type="l")
lines(chi, dchisq(chi, df[6]), lwd = 2, col = col[6], type="l")

legend("topright", legend = paste("k =",df), col = col, lty = 1, bty = "n")
```

## Example

<iframe style="height: 450px;;" src="http://www.tandfonline.com/doi/pdf/10.1080/09589236.2012.708829"></iframe>

## Experiment {.flexbox .vcenter}

<a href="https://www.the-qrcode-generator.com/"><img src="http://chart.apis.google.com/chart?chs=200x200&amp;cht=qr&amp;chld=|1&amp;chl=http%3A%2F%2Fgoo.gl%2Ffaj76B" alt="QR Code" /></a>

http://goo.gl/faj76B

## Data {.smaller}

```{r, echo=FALSE, message=FALSE, warning=FALSE}
# Install if nesserary and load RCurl package
if(!'RCurl' %in% installed.packages()) { install.packages('RCurl') }
library(RCurl)

key = "1yg31q0Q2sEcGq2Y3JaXEEcwsJ5DvDDGzjDbSfAvzZ2c"

# Set google url
google.url <- paste("https://docs.google.com/spreadsheets/d/",key,"/export?format=csv&id=",key, sep='')

# Load csv
myCsv <- getURL(google.url)
# Read csv and assing to data object
data <- read.csv(textConnection(myCsv))

# install.packages("DT")
library("DT")
datatable(data)
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
# setwd('~/Dropbox/UvA/Onderwijs/WSR/Lectures/Sharon/lecture 15 chi square and (partial) correlation')

# Correct variables
data.spss <- data

data.spss$sekse   <- factor(data.spss$sekse,   labels=c(1,2))
data.spss$fluiten <- factor(data.spss$fluiten, labels=c(0,1))

# Write data for use in SPSS
write.table(data.spss, "data.csv", row.names=FALSE, col.names=TRUE, dec=',')
```

## Calculating $\chi^2$ {.subsection}

```{r}
observed <- table(data[,c('fluiten','sekse')])
observed
```

$$\text{observed}_{ij} = 
 \begin{pmatrix}
  `r observed[1,1]` & `r observed[1,2]` \\
  `r observed[2,1]` & `r observed[2,2]` \\
 \end{pmatrix}$$

## Calculating the model {.subsection}

$$\text{model}_{ij} = E_{ij} = \frac{\text{row total}_i \times \text{column total}_j}{n }$$

```{r}
n   = sum(observed)
ct1 = colSums(observed)[1]
ct2 = colSums(observed)[2]
rt1 = rowSums(observed)[1]
rt2 = rowSums(observed)[2]

addmargins(observed)
```


## Calculating the model {.smaller}

$$\text{model}_{ij} = E_{ij} = \frac{\text{row total}_i \times \text{column total}_j}{n }$$

```{r}
model = matrix( c((ct1*rt1)/n,
                  (ct2*rt1)/n,
                  (ct1*rt2)/n,
                  (ct2*rt2)/n),2,2,byrow=T
          )
model
```

$$\text{model}_{ij} = 
 \begin{pmatrix}
  `r model[1,1]` & `r model[1,2]` \\
  `r model[2,1]` & `r model[2,2]` \\
 \end{pmatrix}$$

## observed - model {.subsection}

```{r}
observed - model
```

## Calculating $\chi^2$

$$\chi^2 = \sum \frac{(\text{observed}_{ij} - \text{model}_{ij})^2}{\text{model}_{ij}}$$

```{r}
# Calculate chi squared
chi.squared <- sum((observed - model)^2/model)
chi.squared
```

## Testing for significance {.subsection}

$df = (r - 1) (c - 1)$

```{r}
df = (2 - 1) * ( 2 - 1)

library('visualize')
visualize.chisq(chi.squared,df,section='upper')
```

## Fisher's exact test {.subsection}

Calculates axact $\chi^2$ for small samples

## Likelihood ratio {.subsection}

$$L \chi^2 = 2 \sum \text{observed}_{ij} ln \left( \frac{\text{observed}_{ij}}{\text{model}_{ij}} \right)$$

```{r}
# ln is log
lx2 = 2 * sum(observed * log(observed / model) ); lx2

visualize.chisq(lx2,df,section='upper')
```

## Yates's correction {.subsection}

For 2 x 2 contingency tables.

$$\chi^2 = \sum \frac{ ( | \text{observed}_{ij} - \text{model}_{ij} | - .5)^2}{\text{model}_{ij}}$$

```{r}
# Calculate Yates's corrected chi squared
chi.squared.yates <- sum((abs(observed - model) - .5)^2/model)
chi.squared.yates
visualize.chisq(chi.squared.yates,df,section='upper')
```

## Standardized residuals {.subsection}

$$\text{standardized residuals} = \frac{ \text{observed}_{ij} - \text{model}_{ij} }{ \sqrt{ \text{model}_{ij} } }$$

```{r}
(observed - model) / sqrt(model)
```

## Effect size {.subsection}

Odds ratio based on the model / expected values

```{r, echo=TRUE}
odds <- round( observed, 2); odds
```

$$\begin{pmatrix}
  a & b \\
  c & d \\
 \end{pmatrix}$$
 
$$OR = \frac{a \times d}{b \times c} = \frac{`r odds[1,1]` \times `r odds[2,2]`}{`r odds[1,2]` \times `r odds[2,1]`} = `r (odds[1,1] * odds[2,2]) / (odds[1,2] * odds[2,1])`$$

## Odds

```{r, echo =FALSE}
odds
```

The man and women ratio of people that can whisle and the ratio of those who can't whistle

* Can wistle $\text{Odds}_{mf} = \frac{ `r odds[1,1]` }{ `r odds[1,2]` }$ = `r odds[1,1] / odds[1,2]`
* Can't wistle $\text{Odds}_{mf} = \frac{ `r odds[2,1]` }{ `r odds[2,2]` }$ = `r odds[2,1] / odds[2,2]`

## Odds ratio

Is the ratio of these odds.

$$OR = \frac{\text{wistle}}{\text{can't wistle}} = \frac{`r odds[1,1] / odds[1,2]`}{`r odds[2,1] / odds[2,2]`} = `r (odds[1,1] / odds[1,2]) / (odds[2,1] / odds[2,2])`$$

## Simulation {.subsection .smaller}

```{r}
chi.values = vector()

for(i in 1:1000) {
	
	# Simulate non correlated data
	
	x = rbinom(73,1,.5)
	y = rbinom(73,1,.5)

	data = data.frame(x,y)

	observed <- as.matrix(table(data))

	chi.values[i] = chisq.test(observed,1,correct=FALSE)$statistic

}

hist(chi.values,freq=F)
chi = seq(0,20,.01)
lines(chi,dchisq(chi,1),         lty=1,col='red',  cex=2) # Chi distribution under H0
lines(chi,dchisq(chi,1, ncp = 6),lty=1,col='blue', cex=2) # Chi distribution under HA
```