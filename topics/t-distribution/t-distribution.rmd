# T-distribution {.section}

## Gosset {.smaller}

<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/4/42/William_Sealy_Gosset.jpg/800px-William_Sealy_Gosset.jpg" style="float: left; width: 150px; margin: 0 20px 0 0;">

In probability and statistics, Student's t-distribution (or simply the t-distribution) is any member of a family of continuous probability distributions that arises when estimating the mean of a normally distributed population in situations where the sample size is small and population standard deviation is unknown. 

In the English-language literature it takes its name from William Sealy Gosset's 1908 paper in Biometrika under the pseudonym "Student". Gosset worked at the Guinness Brewery in Dublin, Ireland, and was interested in the problems of small samples, for example the chemical properties of barley where sample sizes might be as low as 3.

Source: [Wikipedia](https://en.wikipedia.org/wiki/Student%27s_t-distribution)

## Population distribution {.smaller .subsection} 

```{r}
layout(matrix(c(2:6,1,1,7:8,1,1,9:13), 4, 4))

n  = 56    # Sample size
df = n - 1 # Degrees of freedom

mu    = 100
sigma = 15

IQ = seq(mu-45, mu+45, 1)

par(mar=c(4,2,2,0))  
plot(IQ, dnorm(IQ, mean = mu, sd = sigma), type='l', col="red", main = "Population Distribution")

n.samples = 12

for(i in 1:n.samples) {
  
  par(mar=c(2,2,2,0))  
  hist(rnorm(n, mu, sigma), main="Sample Distribution", cex.axis=.5, col="red", cex.main = .75)
  
}
```

## T-statistic {.subsection}

$$T_{n-1} = \frac{\bar{x}-\mu}{SE_x} = \frac{\bar{x}-\mu}{s_x / \sqrt{n}}$$

So the t-statistic represents the deviation of the sample mean $\bar{x}$ from the population mean $\mu$, considering the sample size, expressed as the degrees of freedom $df = n - 1$

## A sample {.smaller}

Let's take one sample from our normal populatiion and calculate the t-value.

```{r}
x = rnorm(n, mu, sigma); x

hist(x, main = "Sample distribution", col = "red")
mean(x)
```

## t-value

$$T_{n-1} = \frac{\bar{x}-\mu}{SE_x} = \frac{\bar{x}-\mu}{s_x / \sqrt{n}}$$

```{r}
t = (mean(x) - mu) / (sd(x) / sqrt(n)); t
```

## More samples

let's take more samples.

```{r}
n.samples     = 1000
mean.x.values = vector()
se.x.values   = vector()

for(i in 1:n.samples) {
  x = rnorm(n, mu, sigma)
  mean.x.values[i] = mean(x)
  se.x.values[i]   = (sd(x) / sqrt(n))
}
```

## Mean and SE for all samples

```{r}
head(cbind(mean.x.values, se.x.values))
```

## Samples distribution

```{r}
hist(mean.x.values, 
     col  = "red", 
     main = "Samples distribution", 
     xlab = "all sample means")
```

## Calculate t-values

$$T_{n-1} = \frac{\bar{x}-\mu}{SE_x} = \frac{\bar{x}-\mu}{s_x / \sqrt{n}}$$

```{r}
t.values = (mean.x.values - mu) / se.x.values

tail(cbind(mean.x.values, mu, se.x.values, t.values))
```

## Sampled t-values

What is the distribution of all these t-values?

```{r}
hist(t.values, 
     freq = F, 
     main = "Sampled T-values", 
     xlab = "T-values", 
     ylim = c(0, .4))
T = seq(-4, 4, .01)
lines(T, dt(T,df), col = "red")
legend("topright", lty = 1, col="red", legend = "T-distribution")
```

## T-distribution {.smaller}

So if the population is normaly distributed (assumption of normality) the t-distribution represents the deviation of sample means from the population mean ($\mu$), given a certain sample size ($df = n - 1$). 

The t-distibution therefore is different for different sample sizes and converges to a standard normal distribution if sample size is large enough. 

The t-distribution is defined by:

$$\textstyle\frac{\Gamma \left(\frac{\nu+1}{2} \right)} {\sqrt{\nu\pi}\,\Gamma \left(\frac{\nu}{2} \right)} \left(1+\frac{x^2}{\nu} \right)^{-\frac{\nu+1}{2}}\!$$

Source: [wikipedia](https://en.wikipedia.org/wiki/Student%27s_t-distribution)

```{r, echo=FALSE}
multiple.n  = c(5, 15, 30, 75, 100)
multiple.df = multiple.n - 1
col         = rainbow(length(multiple.df))

plot(T,  dt(T, multiple.df[1]), type = "l", 
     xlim = c(-4,4), ylim = c(0,.45), 
     xlab = "T", ylab="density", 
     col = col[1], main="T-distributions" )

for(i in 2:length(multiple.df)) { 
  
  lines(T, dt(T, multiple.df[i]), type="l", col=col[i])
  } 
legend("topright", legend = paste("n =",multiple.n), lty=1, col = col)
```

## Effect-size {.subsection}

The effect-size is the standardised difference between the mean and the expected $\mu$. In the t-test effect-size is expressed as $r$.

$$r = \sqrt{\frac{t^2}{t^2 + \text{df}}}$$

```{r}
r = sqrt(t^2/(t^2 + df))

r
```

## Effect-size distribution {.smaller}

We can also calculate effect-sizes for all our calculated t-values. Under the assumption of $H_0$ the effect-size distribution looks like this.

```{r, fig.height=3}
r = sqrt(t.values^2/(t.values^2 + df))

tail(cbind(mean.x.values, mu, se.x.values, t.values, r))

hist(r, main = "effect-size distribution", col = "red")
```

Cohen (1988)

* Small: 0 <= .1
* Medium: .1 <= .3
* Large: .3 <= .5

--------

<iframe src="http://rpsychologist.com/d3/NHST/#viz"></iframe>